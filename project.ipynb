{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrystalVision\n",
    "\n",
    "Computer Vision of the *Final Fantasy Trading Card Game (FFTCG)* by Allonte Barakat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal\n",
    "\n",
    "Card games have been around since the 9th century AD; a boon from the new technology of woodblock printing [(Wilkinson, 1895)](https://zenodo.org/record/1448960). These games have made it across centuries and across continents giving use the recognizable French-suited 52-card deck - cards that have relatively simple anatomy; each one has a rank, a suit, and is the relatively the same if flipped 180-degrees.\n",
    "\n",
    "Introduced in 1993 with *Magic: The Gathering*, trading card games are great advancement on card games and a great learning tools for learning building, strategy, and dynamic responses [(Turkay et al., 2012)](https://doi.org/10.1016%2Fj.sbspro.2012.06.130). Today, the anatomy of cards in games like the *Final Fantasy Trading Card Game* are complex yet easily human recognizable.\n",
    "\n",
    "As outlined in David Forsyth and Jean Ponce's *Computer Vision: A Modern Approach*, recognition is one of Computer Vision's typical tasks. This act of recognition can come in the differing varieties of object classification, identification, and detection. For this project, I will be tackling recognition as best as possible. Beginning with classification step, I will make different models using the same inputs mapping to different outputs based on the card's anatomy, such as, *element*, *type*, *power*, *artist*, etc. I will also research on multi-class classification and see what techniques (if such exist publically) could be utilized. I hypothesize that the identity of a card can be derived by taking all these elements and traversing a graph-database. The larger stretch goal of being able to perform object detection via video (webcam) feed would enable the ultimate real-world application of playing games across languages or displaying the current prices for the purpose of trading.\n",
    "\n",
    "Another interesting potential, if integrated with AR, could provided more experiental novelties by overlaying clips from the game or a AR-avatar over the card. The full-scale recognition, through the use of a CNN (likely ResNet model), could help with an in medias res AI analysis of potential strategies to aid a play to make the best plays. The environment being so stochastic, at least in comparison to a chess board, makes such applications, even in terms of model-representations interesting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edje Electronics's Approach\n",
    "\n",
    "Their YouTube video can be found [here](https://www.youtube.com/watch?v=m-QPjO-2IkA). Additionally, their GitHub for this project can be found [here](https://github.com/EdjeElectronics/OpenCV-Playing-Card-Detector).\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/m-QPjO-2IkA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n",
    "\n",
    "By taking the standard deck as the basis, this person has used non-ML detection to identify the cards. By using a simple/stable background and applying gaussian blur on a grayscale image, they then find contours after some thresholding. After finding such contours, the image is then warped to the standard facing card and a manual comparison between stored images of the rank/suit for the deck is then compared to determine what card it is.\n",
    "\n",
    "This is a very manual effort that is only feasible for a specific deck-printing and the limited nature of the deck. In TCGs, hundreds of new cards get released every few months."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethan's Approach\n",
    "\n",
    "Their YouTube video can be found [here](https://www.youtube.com/watch?v=BZGhRSajyb). No source code is availible for the public.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BZGhRSajybk\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n",
    "\n",
    "This person has attempted detection in similar way but applying it a small to *Magic: the Gathering* cards (per set). In essence by greatly reducing the pool of possible cards, polling the top amount of pixels that would the cards *name*, and applying OCR the card can be identified. This approach heavily relies on the legibility (high enough DPI/megapixels) and can be prone to error depending on the OCR technique and/or library.\n",
    "\n",
    "Once again, a very manual effort that cannot differentiate between languages or different art styles or printing processes -- all of which directly affect a card's value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card Anatomy\n",
    "\n",
    "The anatomy of a card are the identifiable features. With good graphic design, the major features are the most visually prominent. *Final Fantasy Trading Card Game* (FFTCG) has over 2600 unique cards and at least 11 features - where I would consider, at minimum, 5 to be major features: *name*, *element*, *type*, *cost*, *power*. These would be the primary things I would train, as the more minor features such *illustrator* would be useful to break identification ties."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "In the upper portion of the card, on top of stylized boxes to mirror the card type, is the name of the card.\n",
    "\n",
    "### Element\n",
    "In FFTCG, there are 8 primary elements as follows: *lightning*, *fire*, *wind*, *ice*, *earth*, *water*, *light*, and *dark*. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://ffdecks.com/assets/lightning.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/fire.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/wind.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/ice.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/earth.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/water.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/light.png\" /></td>\n",
    "        <td><img src=\"https://ffdecks.com/assets/dark.png\" /></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "This is often one of the most major considerations in deck building and evolving a strategy. Second to that, there are some cards that can be more than one element at the same time, for this project, I will consider not adding these to the dataset for simplicity.\n",
    "\n",
    "### Cost\n",
    "While you can see the element by the color of the frame, the symbol behind the text, and the color of the crystal in the upper-left corner -- cost can only be see in the number in the upper-left corner.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/5-019L_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/8-035H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/18-040H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/2-093H_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/6-096C_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/18-097R_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/8-133H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/11-130L_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type\n",
    "The main card *types* are: *forward*, *backup*. *summon*, or *monster*. In general there are no cards that current exist that are the same time at the same type. The closest are *monsters* that can become a *forward* by some effect written on the card.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/18-026L_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/2-041H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/9-025H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/16-038H_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power\n",
    "\n",
    "Power always exists on *forward* types and some *monster* types; both having differing font-effects to signify the nature of always having the feature or sometimes having the feature. In very rare cases, a backup could have power.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/16-007R_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/16-010H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/17-012R_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Cases\n",
    "As the game progresses, it is entirely possible to run in the corner case of identifing all the same features but not able to do the final step of resolving to some unique id (such as 1-210S and 10-101L below). Some other uniqueness idenitifer would also need to be used, perhaps a minor feature such as *illustrator* or *job*.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-210S_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/10-101L_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To support FFTCG, Square Enix has a [*Card Browser*](https://fftcg.square-enix-games.com/na/card-browser) on its site. From here we can pull offical images (in 429x600 full-size or 179x250 thumb-size) in various languages and printings. By pooling and training on such data, it is possible to be current with each new set or special printing. Moreover, the exposed api allows us to use their feature-query data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Code': '12-002H',\n",
       " 'Element': '火',\n",
       " 'Rarity': 'H',\n",
       " 'Cost': '3',\n",
       " 'Power': '',\n",
       " 'Category_1': 'FFEX',\n",
       " 'Category_2': '',\n",
       " 'Multicard': '',\n",
       " 'Ex_Burst': '',\n",
       " 'Name': 'アマテラス',\n",
       " 'Type': '召喚獣',\n",
       " 'Job': '',\n",
       " 'Text': 'オートアビリティ1つを選ぶ。それの効果を無効にする。それを発動しているのがフォワードの場合、そのフォワードに8000ダメージを与える。',\n",
       " 'Name_EN': 'Amaterasu',\n",
       " 'Type_EN': 'Summon',\n",
       " 'Job_EN': '',\n",
       " 'Text_EN': 'Choose 1 auto-ability. Cancel its effect. If the cancelled auto-ability triggered from a Forward, deal that Forward 8000 damage.',\n",
       " 'Name_DE': 'Amaterasu',\n",
       " 'Type_DE': 'Beschwörung',\n",
       " 'Job_DE': '',\n",
       " 'Text_DE': 'Wähle 1 Auto-Fähigkeit aus. Annulliere deren Effekt. Falls die annullierte Auto-Fähigkeit die eines Stürmers war, füge diesem Stürmer 8000 Schaden zu.',\n",
       " 'Name_ES': 'Amaterasu',\n",
       " 'Type_ES': 'Invocación',\n",
       " 'Job_ES': '',\n",
       " 'Text_ES': 'Elige 1 habilidad de apoyo. Cancela su efecto. Si la habilidad de apoyo cancelada pertenecía a un Delantero, inflígele a ese Delantero 8000 puntos de daño.',\n",
       " 'Name_FR': 'Amaterasu',\n",
       " 'Type_FR': 'Invocation',\n",
       " 'Job_FR': '',\n",
       " 'Text_FR': 'Choisissez 1 compétence auto. Annulez son effet. Si la compétence auto appartenait à un Avant, infligez 8000 points de dégâts à cet Avant.',\n",
       " 'Name_IT': 'Amaterasu',\n",
       " 'Type_IT': 'Evocazione',\n",
       " 'Job_IT': '',\n",
       " 'Text_IT': \"Scegli 1 autoabilità. Annullane l'effetto. Se l'autoabilità annullata apparteneva a un'Avanguardia, infliggi 8000 punti di danno a quell'Avanguardia.\",\n",
       " 'Set': 'Opus XII',\n",
       " 'Text_NA': 'Choose 1 auto-ability. Cancel its effect. If the cancelled auto-ability triggered from a Forward, deal that Forward 8000 damage.',\n",
       " 'Job_NA': '',\n",
       " 'Type_NA': 'Summon',\n",
       " 'Name_NA': 'Amaterasu',\n",
       " 'images': {'thumbs': ['https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_eg.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_eg_FL.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_de.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_es.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_fr.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_it.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_de_FL.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_es_FL.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_fr_FL.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_it_FL.jpg'],\n",
       "  'full': ['https://fftcg.cdn.sewest.net/images/cards/full/12-002H_eg.jpg',\n",
       "   'https://fftcg.cdn.sewest.net/images/cards/full/12-002H_eg_FL.jpg']}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"Code\": \"12-002H\",\n",
    "    \"Element\": \"\\u706b\",\n",
    "    \"Rarity\": \"H\",\n",
    "    \"Cost\": \"3\",\n",
    "    \"Power\": \"\",\n",
    "    \"Category_1\": \"FFEX\",\n",
    "    \"Category_2\": \"\",\n",
    "    \"Multicard\": \"\",\n",
    "    \"Ex_Burst\": \"\",\n",
    "    \"Name\": \"\\u30a2\\u30de\\u30c6\\u30e9\\u30b9\",\n",
    "    \"Type\": \"\\u53ec\\u559a\\u7363\",\n",
    "    \"Job\": \"\",\n",
    "    \"Text\": \"\\u30aa\\u30fc\\u30c8\\u30a2\\u30d3\\u30ea\\u30c6\\u30a31\\u3064\\u3092\\u9078\\u3076\\u3002\\u305d\\u308c\\u306e\\u52b9\\u679c\\u3092\\u7121\\u52b9\\u306b\\u3059\\u308b\\u3002\\u305d\\u308c\\u3092\\u767a\\u52d5\\u3057\\u3066\\u3044\\u308b\\u306e\\u304c\\u30d5\\u30a9\\u30ef\\u30fc\\u30c9\\u306e\\u5834\\u5408\\u3001\\u305d\\u306e\\u30d5\\u30a9\\u30ef\\u30fc\\u30c9\\u306b8000\\u30c0\\u30e1\\u30fc\\u30b8\\u3092\\u4e0e\\u3048\\u308b\\u3002\",\n",
    "    \"Name_EN\": \"Amaterasu\",\n",
    "    \"Type_EN\": \"Summon\",\n",
    "    \"Job_EN\": \"\",\n",
    "    \"Text_EN\": \"Choose 1 auto-ability. Cancel its effect. If the cancelled auto-ability triggered from a Forward, deal that Forward 8000 damage.\",\n",
    "    \"Name_DE\": \"Amaterasu\",\n",
    "    \"Type_DE\": \"Beschw\\u00f6rung\",\n",
    "    \"Job_DE\": \"\",\n",
    "    \"Text_DE\": \"W\\u00e4hle 1 Auto-F\\u00e4higkeit aus. Annulliere deren Effekt. Falls die annullierte Auto-F\\u00e4higkeit die eines St\\u00fcrmers war, f\\u00fcge diesem St\\u00fcrmer 8000 Schaden zu.\",\n",
    "    \"Name_ES\": \"Amaterasu\",\n",
    "    \"Type_ES\": \"Invocaci\\u00f3n\",\n",
    "    \"Job_ES\": \"\",\n",
    "    \"Text_ES\": \"Elige 1 habilidad de apoyo. Cancela su efecto. Si la habilidad de apoyo cancelada pertenec\\u00eda a un Delantero, infl\\u00edgele a ese Delantero 8000 puntos de da\\u00f1o.\",\n",
    "    \"Name_FR\": \"Amaterasu\",\n",
    "    \"Type_FR\": \"Invocation\",\n",
    "    \"Job_FR\": \"\",\n",
    "    \"Text_FR\": \"Choisissez 1 comp\\u00e9tence auto. Annulez son effet. Si la comp\\u00e9tence auto appartenait \\u00e0 un Avant, infligez 8000 points de d\\u00e9g\\u00e2ts \\u00e0 cet Avant.\",\n",
    "    \"Name_IT\": \"Amaterasu\",\n",
    "    \"Type_IT\": \"Evocazione\",\n",
    "    \"Job_IT\": \"\",\n",
    "    \"Text_IT\": \"Scegli 1 autoabilit\\u00e0. Annullane l'effetto. Se l'autoabilit\\u00e0 annullata apparteneva a un'Avanguardia, infliggi 8000 punti di danno a quell'Avanguardia.\",\n",
    "    \"Set\": \"Opus XII\",\n",
    "    \"Text_NA\": \"Choose 1 auto-ability. Cancel its effect. If the cancelled auto-ability triggered from a Forward, deal that Forward 8000 damage.\",\n",
    "    \"Job_NA\": \"\",\n",
    "    \"Type_NA\": \"Summon\",\n",
    "    \"Name_NA\": \"Amaterasu\",\n",
    "    \"images\": {\n",
    "        \"thumbs\": [\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_eg.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_eg_FL.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_de.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_es.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_fr.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_it.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_de_FL.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_es_FL.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_fr_FL.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/thumbs/12-002H_it_FL.jpg\"\n",
    "        ],\n",
    "        \"full\": [\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/full/12-002H_eg.jpg\",\n",
    "            \"https://fftcg.cdn.sewest.net/images/cards/full/12-002H_eg_FL.jpg\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Omitted\n",
    "\n",
    "Under the prudent auspice of the KISS (Keep It Simple Stupid) principle, one must consider what data to decline to use (at least initially)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19122, 38)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "from data.dataset import make_database\n",
    "\n",
    "# running gatherdata.py is required to get the data\n",
    "cards = make_database()\n",
    "\n",
    "# (Amount of cards, API-Features)\n",
    "print(cards.shape)\n",
    "\n",
    "# (Number of images, API-Features)\n",
    "cards = cards.explode(\"thumbs\")\n",
    "cards.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, let's removing Crystal tokens. Tokens are really like reminder-marker pieces.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/C-001_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/C-005_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19092, 38)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards.query(\"type_en != 'Crystal'\", inplace=True)\n",
    "cards.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also remove Boss Battle cards. These are special cards, with special frames, only to be used in a specific multiplayer deck.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/B-027_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/B-028_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/B-042_eg.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18822, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards.query(\"rarity != 'B'\", inplace=True)\n",
    "cards.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also remove Full Art cards. These are cards with the same code as another card but have the frame removed, thus, likely harder for a machine to detect some features.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/16-007R_eg_FL.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-107L_eg_FL.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/15-090H_eg_FL.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/19-075C_eg_FL.jpg\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17462, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards.query(f\"~thumbs.str.contains('_FL') and ~thumbs.str.contains('_2_')\", inplace=True)\n",
    "cards.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also remove Promo cards. These are alternate art or with special words stamped cards given out as prizes.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"http://www.square-enix-shop.com/jp/ff-tcg/card/cimg/large/pr/PR-124.png\" /></td>\n",
    "        <td><img src=\"http://www.square-enix-shop.com/jp/ff-tcg/card/cimg/large/pr/PR-118.png\" /></td>\n",
    "        <td><img src=\"http://www.square-enix-shop.com/jp/ff-tcg/card/cimg/large/pr/PR-104.png\" /></td>\n",
    "        <td><img src=\"http://www.square-enix-shop.com/jp/ff-tcg/card/cimg/large/pr/PR-057.png\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17325, 38)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards.query(f\"~thumbs.str.contains('_PR')\", inplace=True)\n",
    "cards.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also remove *some* different language cards. By adding 1 lanuage we double our pool and fix issues with certain stratifications.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-176H_eg.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-176H_de.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-176H_es.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-176H_fr.jpg\" /></td>\n",
    "        <td><img src=\"https://fftcg.cdn.sewest.net/images/cards/full/1-176H_it.jpg\" /></td>\n",
    "        <td><img src=\"http://www.square-enix-shop.com/jp/ff-tcg/card/cimg/large/opus1/1-176H.png\" /></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5780, 38)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore by language, commented out means keeping in data\n",
    "# cards.query(f\"~thumbs.str.contains('_eg')\", inplace=True)  # English\n",
    "cards.query(f\"~thumbs.str.contains('_fr')\", inplace=True)  # French\n",
    "# cards.query(f\"~thumbs.str.contains('_es')\", inplace=True)  # Spanish\n",
    "cards.query(f\"~thumbs.str.contains('_it')\", inplace=True)  # Italian\n",
    "cards.query(f\"~thumbs.str.contains('_de')\", inplace=True)  # German\n",
    "cards.query(f\"~thumbs.str.contains('_jp')\", inplace=True)  # Japanese\n",
    "cards.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technologies\n",
    "\n",
    "### Data Stratification\n",
    "\n",
    "After we select which data (images) we will use, we must split the data between training and test. By using `sklearn`'s `train_test_split` function we can split the data effectively by using its `stratify=` kwarg which will ensure that there will there is some percentage of of unique strafied features are in training and test. Our model would not be effective if we have never, by random chance, validated against *Ice-Element, Monster-Type_EN* cards.\n",
    "\n",
    "For concistency, it is best to make sure the factorization is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get our catergorical label/classes\n",
    "codes, uniques = cards[\"element\"].factorize(sort=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cards[\"thumbs\"],\n",
    "                                                    codes,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=cards[[\"element\", \"type_en\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For more robust models, we should consider some pertubations. For example, the card is flipped upside-down; this is how one would view the opponent's card from across the table. This will effectively double our training and test data post-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7744"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils.image_dataset import paths_and_labels_to_dataset\n",
    "\n",
    "training_dataset = paths_and_labels_to_dataset(\n",
    "    image_paths=X_train.tolist(),\n",
    "    image_size=(250, 179),\n",
    "    num_channels=3,\n",
    "    labels=y_train.tolist(),\n",
    "    label_mode='categorical',\n",
    "    num_classes=len(uniques),\n",
    "    interpolation=\"bilinear\",\n",
    ")\n",
    "\n",
    "flipped_training_dataset= training_dataset.map(lambda x, y: (tf.image.flip_up_down(x), y))\n",
    "training_dataset = training_dataset.concatenate(flipped_training_dataset)\n",
    "training_dataset.cardinality().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "#### Pooling\n",
    "\n",
    "Models must be hand-crafted per feature; some require more hidden layers while others, like *Element* model benifit from using `AveragePooling2D` between the first two `Conv2D` layers. `AveragePooling2D` acts almost like a blur; with frames the overall color of the frame feels like a likely solution than any one specific card-feature. `MaxPooling2D` covers alot of waht is needed as it gets some maximal from a batch. With the majority of have more negative space or on a light background, this is an effective layer.\n",
    "\n",
    "Pooling with a white background\n",
    "<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*OSAjz9_Ll-AICg0xru2nUQ.png' />\n",
    "\n",
    "Pooling with a dark backhround\n",
    "<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*fpmtYoP9e8hycFIILPfW5A.png' />\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*HinFZ5XQKP_Lc2YY0Esh6A.png\" />\n",
    "\n",
    "Check the article [Maxpooling vs minpooling vs average pooling](https://medium.com/@bdhuma/which-pooling-method-is-better-maxpooling-vs-minpooling-vs-average-pooling-95fb03f45a9) for more information.\n",
    "\n",
    "#### Optimizers\n",
    "\n",
    "Crafting the models was alot of trail and error. In many cases, there were hardware limitations, thus complex and intensive models could not be created. Moreover, the real-world accuracy of the model can vary wildly depending on the optimizer used. \n",
    "\n",
    "In the majority of my models, `RMSprop` was one of the most effective categorical optimizers.\n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:640/format:webp/1*z2iT5iFhDOnHU6AtC2xITg.png' />\n",
    "\n",
    "Second to that, `Nesterov` (Nesterov Accelerated Gradient - specialized `SGD`) was effective in the others.\n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:640/format:webp/1*LpMapdBCvjKvqwEArDndIg.png' />\n",
    "\n",
    "Check the article [](https://firiuza.medium.com/optimizers-for-training-neural-networks-e0196662e21e) for more details.\n",
    "\n",
    "For my binary classification (of *Ex_Burst*), I decided to use ensemble modeling.\n",
    "\n",
    "#### Ensemble Model\n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*surWujKv0sqceD1kOYpqtQ.png' />\n",
    "\n",
    "By using multi models together, it is possible to have an accuracy that is greater than any one. `scikit-learn` has some great documentation on some approached to [ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html). \n",
    "\n",
    "After creating multiple models for *Ex_Burst* (mostly using different optimizers), I settled on using `VotingClassifier` using hard (`np.bincount`) based choices rather than soft (average). The quirk is this method from the module requires the model to run `.fit()` in order to be used. As the models were already fitted before in `generatemodels.py`, I needed to extend-customize the class myself. (A future work item is to then save this practice `keras` model to disk so that it could be used by other libraries like `openCV`.)\n",
    "\n",
    "### Real-World Accuracy\n",
    "In `testmodels.py` I maintain list of `IMAGES` and a `pd.DataFrame` of accurate card feature data. This lets me easily expand and review the accuracy of each feature model. For instance, my *Element* model will not only show is accuracy percentage but in the DataFrame show the values it has classified in the `Element_yhat` column. There is also potential for some issues with the test image data due to images needing to be downsampled. Under (Pillow's Filter documentation)[https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-filters], `LANCZOS` was selected as the best filter; even though it has poor performance by comparison, it offers the best up/down scaling quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find d:\\CrystalVision\\./src\\data\\..\\..\\data\\model\\name_en.json, skipping...\n",
      "Cannot find d:\\CrystalVision\\./src\\data\\..\\..\\data\\model\\element.json, skipping...\n",
      "Cannot find d:\\CrystalVision\\./src\\data\\..\\..\\data\\model\\type_en.json, skipping...\n",
      "Cannot find d:\\CrystalVision\\./src\\data\\..\\..\\data\\model\\cost.json, skipping...\n",
      "Cannot find d:\\CrystalVision\\./src\\data\\..\\..\\data\\model\\power.json, skipping...\n",
      "2/2 [==============================] - 2s 126ms/step\n",
      "          ex_burst_yhat\n",
      "ex_burst               \n",
      "0          6.807491e-07\n",
      "1          7.257171e-06           ex_burst_yhat\n",
      "ex_burst               \n",
      "0              0.997913\n",
      "1              0.987876\n",
      "         ex_burst  ex_burst_yhat\n",
      "code                            \n",
      "19-111L         0   9.970247e-01\n",
      "20-007L         0   1.191080e-04\n",
      "1-107L          0   5.470494e-03\n",
      "8-135H          0   5.348144e-04\n",
      "4-066R          0   8.166118e-03\n",
      "14-123C         0   9.959382e-01\n",
      "13-103L         0   6.807491e-07\n",
      "7-098R          0   2.540107e-03\n",
      "18-130L         0   9.739038e-02\n",
      "6-074C          0   2.119989e-04\n",
      "12-037L         0   4.692804e-05\n",
      "12-120C         0   9.073267e-01\n",
      "5-091H          1   1.450022e-03\n",
      "10-132S         1   9.878763e-01\n",
      "18-123L         1   7.253580e-05\n",
      "4-145H          1   4.638270e-03\n",
      "18-139S         1   7.257171e-06\n",
      "19-107C         1   2.007056e-04\n",
      "7-031C          1   7.844559e-04\n",
      "13-115L         1   3.094027e-05\n",
      "7-045C          1   6.378794e-04\n",
      "17-094C         1   1.743877e-02\n",
      "17-080R         1   9.805865e-01\n",
      "2-137H          1   3.714130e-03\n",
      "       message: Optimization terminated successfully.\n",
      "       success: True\n",
      "        status: 0\n",
      "           fun: 0.5416666666666667\n",
      "             x: [ 2.088e-01]\n",
      "           nit: 8\n",
      "          nfev: 23\n",
      " final_simplex: (array([[ 2.088e-01],\n",
      "                       [ 2.089e-01]]), array([ 5.417e-01,  5.417e-01]))\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.5\n",
      "       x: [ 9.415e-01]\n",
      "     nit: 2\n",
      "   direc: [[ 1.000e+00]]\n",
      "    nfev: 40\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.5416666666666667\n",
      "       x: [ 2.088e-01]\n",
      "     nit: 0\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      "    njev: 1\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.5416666666666667\n",
      "        x: [ 2.088e-01]\n",
      "      nit: 0\n",
      "      jac: [ 0.000e+00]\n",
      " hess_inv: [[1]]\n",
      "     nfev: 2\n",
      "     njev: 1\n",
      "newton-cg\n",
      "Jacobian is required for Newton-CG method\n",
      "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.5416666666666667\n",
      "        x: [ 2.088e-01]\n",
      "      nit: 0\n",
      "      jac: [ 0.000e+00]\n",
      "     nfev: 2\n",
      "     njev: 1\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      " message: Local minimum reached (|pg| ~= 0)\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.5416666666666667\n",
      "       x: [ 2.088e-01]\n",
      "     nit: 0\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method cg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method bfgs cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method newton-cg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method cobyla cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: 0.5\n",
      "       x: [ 1.209e+00]\n",
      "    nfev: 8\n",
      "   maxcv: 0.0\n",
      " message: Optimization terminated successfully\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.5416666666666667\n",
      "       x: [ 2.088e-01]\n",
      "     nit: 1\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      "    njev: 1\n",
      "           message: `gtol` termination condition is satisfied.\n",
      "           success: True\n",
      "            status: 1\n",
      "               fun: 0.5416666666666667\n",
      "                 x: [ 3.646e-01]\n",
      "               nit: 12\n",
      "              nfev: 6\n",
      "              njev: 3\n",
      "              nhev: 0\n",
      "          cg_niter: 2\n",
      "      cg_stop_cond: 0\n",
      "              grad: [ 0.000e+00]\n",
      "   lagrangian_grad: [-5.396e-09]\n",
      "            constr: [array([ 3.646e-01])]\n",
      "               jac: [<1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "                    \twith 1 stored elements in Compressed Sparse Row format>]\n",
      "       constr_nfev: [0]\n",
      "       constr_njev: [0]\n",
      "       constr_nhev: [0]\n",
      "                 v: [array([-5.396e-09])]\n",
      "            method: tr_interior_point\n",
      "        optimality: 5.395757665451155e-09\n",
      "  constr_violation: 0.0\n",
      "    execution_time: 0.10086727142333984\n",
      "         tr_radius: 9357041.61942578\n",
      "    constr_penalty: 1.0\n",
      " barrier_parameter: 5.120000000000003e-08\n",
      " barrier_tolerance: 5.120000000000003e-08\n",
      "             niter: 12\n",
      "dogleg\n",
      "Jacobian is required for dogleg minimization\n",
      "trust-ncg\n",
      "Jacobian is required for Newton-CG trust-region minimization\n",
      "trust-exact\n",
      "Jacobian is required for trust region exact minimization.\n",
      "trust-krylov\n",
      "('Jacobian is required for trust region ', 'exact minimization.')\n",
      "[0.94151541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method dogleg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-ncg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-exact cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-krylov cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n",
      "           multicard_yhat\n",
      "multicard                \n",
      "0                0.000002\n",
      "1                0.000996            multicard_yhat\n",
      "multicard                \n",
      "0                0.987367\n",
      "1                0.161171\n",
      "         multicard  multicard_yhat\n",
      "code                              \n",
      "12-037L          0        0.001835\n",
      "20-007L          0        0.000062\n",
      "1-184H           0        0.954334\n",
      "7-089C           1        0.058742\n",
      "7-098R           1        0.000996\n",
      "4-058C           1        0.161171\n",
      "       message: Optimization terminated successfully.\n",
      "       success: True\n",
      "        status: 0\n",
      "           fun: 0.6666666666666667\n",
      "             x: [ 1.962e-01]\n",
      "           nit: 8\n",
      "          nfev: 23\n",
      " final_simplex: (array([[ 1.962e-01],\n",
      "                       [ 1.963e-01]]), array([ 6.667e-01,  6.667e-01]))\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.6666666666666667\n",
      "       x: [ 9.543e-01]\n",
      "     nit: 1\n",
      "   direc: [[ 1.000e+00]]\n",
      "    nfev: 21\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.6666666666666667\n",
      "       x: [ 1.962e-01]\n",
      "     nit: 0\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      "    njev: 1\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.6666666666666667\n",
      "        x: [ 1.962e-01]\n",
      "      nit: 0\n",
      "      jac: [ 0.000e+00]\n",
      " hess_inv: [[1]]\n",
      "     nfev: 2\n",
      "     njev: 1\n",
      "newton-cg\n",
      "Jacobian is required for Newton-CG method\n",
      "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.6666666666666667\n",
      "        x: [ 1.962e-01]\n",
      "      nit: 0\n",
      "      jac: [ 0.000e+00]\n",
      "     nfev: 2\n",
      "     njev: 1\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      " message: Local minimum reached (|pg| ~= 0)\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.6666666666666667\n",
      "       x: [ 1.962e-01]\n",
      "     nit: 0\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: 0.5\n",
      "       x: [ 1.196e+00]\n",
      "    nfev: 8\n",
      "   maxcv: 0.0\n",
      " message: Optimization terminated successfully\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.6666666666666667\n",
      "       x: [ 1.962e-01]\n",
      "     nit: 1\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      "    njev: 1\n",
      "           message: `gtol` termination condition is satisfied.\n",
      "           success: True\n",
      "            status: 1\n",
      "               fun: 0.6666666666666667\n",
      "                 x: [ 3.487e-01]\n",
      "               nit: 12\n",
      "              nfev: 6\n",
      "              njev: 3\n",
      "              nhev: 0\n",
      "          cg_niter: 2\n",
      "      cg_stop_cond: 0\n",
      "              grad: [ 0.000e+00]\n",
      "   lagrangian_grad: [-5.213e-09]\n",
      "            constr: [array([ 3.487e-01])]\n",
      "               jac: [<1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "                    \twith 1 stored elements in Compressed Sparse Row format>]\n",
      "       constr_nfev: [0]\n",
      "       constr_njev: [0]\n",
      "       constr_nhev: [0]\n",
      "                 v: [array([-5.213e-09])]\n",
      "            method: tr_interior_point\n",
      "        optimality: 5.213437914302311e-09\n",
      "  constr_violation: 0.0\n",
      "    execution_time: 0.054927825927734375\n",
      "         tr_radius: 9258179.885462072\n",
      "    constr_penalty: 1.0\n",
      " barrier_parameter: 5.120000000000003e-08\n",
      " barrier_tolerance: 5.120000000000003e-08\n",
      "             niter: 12\n",
      "dogleg\n",
      "Jacobian is required for dogleg minimization\n",
      "trust-ncg\n",
      "Jacobian is required for Newton-CG trust-region minimization\n",
      "trust-exact\n",
      "Jacobian is required for trust region exact minimization.\n",
      "trust-krylov\n",
      "('Jacobian is required for trust region ', 'exact minimization.')\n",
      "[1.19618982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method cg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method bfgs cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method newton-cg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method cobyla cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method dogleg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-ncg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-exact cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-krylov cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 13ms/step\n",
      "          mono_yhat\n",
      "mono               \n",
      "False  2.319447e-13\n",
      "True   4.669110e-14        mono_yhat\n",
      "mono            \n",
      "False   0.999980\n",
      "True    0.996422\n",
      "          mono     mono_yhat\n",
      "code                        \n",
      "13-119L  False  9.946195e-01\n",
      "12-119L  False  4.717071e-10\n",
      "13-115L  False  9.999384e-01\n",
      "14-123C  False  2.793180e-09\n",
      "18-123L  False  9.999800e-01\n",
      "19-111L  False  4.463756e-08\n",
      "12-120C  False  3.580448e-07\n",
      "18-107L  False  2.077490e-09\n",
      "18-130L  False  2.094996e-01\n",
      "18-128H  False  1.281335e-06\n",
      "19-107C  False  9.991925e-01\n",
      "19-127L  False  2.319447e-13\n",
      "18-139S  False  4.204689e-02\n",
      "1-107L    True  4.796643e-04\n",
      "1-044R    True  8.336706e-08\n",
      "11-065H   True  9.964217e-01\n",
      "17-080R   True  4.231083e-07\n",
      "8-135H    True  5.016792e-08\n",
      "1-184H    True  5.207488e-05\n",
      "7-098R    True  1.108451e-01\n",
      "4-058C    True  1.155331e-10\n",
      "4-066R    True  1.835004e-03\n",
      "17-094C   True  3.654874e-02\n",
      "4-145H    True  6.728682e-07\n",
      "18-100L   True  8.790159e-05\n",
      "12-037L   True  8.773338e-10\n",
      "       message: Optimization terminated successfully.\n",
      "       success: True\n",
      "        status: 0\n",
      "           fun: 0.34615384615384615\n",
      "             x: [ 2.074e-01]\n",
      "           nit: 8\n",
      "          nfev: 22\n",
      " final_simplex: (array([[ 2.074e-01],\n",
      "                       [ 2.073e-01]]), array([ 3.462e-01,  3.462e-01]))\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.3846153846153846\n",
      "       x: [ 9.869e-01]\n",
      "     nit: 1\n",
      "   direc: [[ 1.000e+00]]\n",
      "    nfev: 21\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.34615384615384615\n",
      "       x: [ 2.074e-01]\n",
      "     nit: 0\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      "    njev: 1\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.34615384615384615\n",
      "        x: [ 2.074e-01]\n",
      "      nit: 0\n",
      "      jac: [ 0.000e+00]\n",
      " hess_inv: [[1]]\n",
      "     nfev: 2\n",
      "     njev: 1\n",
      "newton-cg\n",
      "Jacobian is required for Newton-CG method\n",
      "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.34615384615384615\n",
      "        x: [ 2.074e-01]\n",
      "      nit: 0\n",
      "      jac: [ 0.000e+00]\n",
      "     nfev: 2\n",
      "     njev: 1\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      " message: Local minimum reached (|pg| ~= 0)\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.34615384615384615\n",
      "       x: [ 2.074e-01]\n",
      "     nit: 0\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method cg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method bfgs cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method newton-cg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method cobyla cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: 0.34615384615384615\n",
      "       x: [ 2.074e-01]\n",
      "    nfev: 11\n",
      "   maxcv: 0.0\n",
      " message: Optimization terminated successfully\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.34615384615384615\n",
      "       x: [ 2.074e-01]\n",
      "     nit: 1\n",
      "     jac: [ 0.000e+00]\n",
      "    nfev: 2\n",
      "    njev: 1\n",
      "           message: `gtol` termination condition is satisfied.\n",
      "           success: True\n",
      "            status: 1\n",
      "               fun: 0.3846153846153846\n",
      "                 x: [ 3.646e-01]\n",
      "               nit: 12\n",
      "              nfev: 6\n",
      "              njev: 3\n",
      "              nhev: 0\n",
      "          cg_niter: 2\n",
      "      cg_stop_cond: 0\n",
      "              grad: [ 0.000e+00]\n",
      "   lagrangian_grad: [-5.442e-09]\n",
      "            constr: [array([ 3.646e-01])]\n",
      "               jac: [<1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "                    \twith 1 stored elements in Compressed Sparse Row format>]\n",
      "       constr_nfev: [0]\n",
      "       constr_njev: [0]\n",
      "       constr_nhev: [0]\n",
      "                 v: [array([-5.442e-09])]\n",
      "            method: tr_interior_point\n",
      "        optimality: 5.4415163489130885e-09\n",
      "  constr_violation: 0.0\n",
      "    execution_time: 0.10136651992797852\n",
      "         tr_radius: 9370540.06389826\n",
      "    constr_penalty: 1.0\n",
      " barrier_parameter: 5.120000000000003e-08\n",
      " barrier_tolerance: 5.120000000000003e-08\n",
      "             niter: 12\n",
      "dogleg\n",
      "Jacobian is required for dogleg minimization\n",
      "trust-ncg\n",
      "Jacobian is required for Newton-CG trust-region minimization\n",
      "trust-exact\n",
      "Jacobian is required for trust region exact minimization.\n",
      "trust-krylov\n",
      "('Jacobian is required for trust region ', 'exact minimization.')\n",
      "[0.20736729]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method dogleg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-ncg cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-exact cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n",
      "d:\\CrystalVision\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:569: RuntimeWarning: Method trust-krylov cannot handle bounds.\n",
      "  warn('Method %s cannot handle bounds.' % method,\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'name_en_yhat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\CrystalVision\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\CrystalVision\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\CrystalVision\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name_en_yhat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[39m=\u001b[39m test_models()\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m category \u001b[39min\u001b[39;00m CATEGORIES:\n\u001b[1;32m----> 6\u001b[0m     comp \u001b[39m=\u001b[39m df[category] \u001b[39m==\u001b[39m df[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcategory\u001b[39m}\u001b[39;49;00m\u001b[39m_yhat\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m      7\u001b[0m     comp \u001b[39m=\u001b[39m comp\u001b[39m.\u001b[39mvalue_counts(normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcategory\u001b[39m}\u001b[39;00m\u001b[39m accuracy: \u001b[39m\u001b[39m{\u001b[39;00mcomp[\u001b[39mTrue\u001b[39;00m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\CrystalVision\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\CrystalVision\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name_en_yhat'"
     ]
    }
   ],
   "source": [
    "from testmodels import CATEGORIES, test_models\n",
    "\n",
    "df = test_models()\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    comp = df[category] == df[f\"{category}_yhat\"]\n",
    "    comp = comp.value_counts(normalize=True)\n",
    "    print(f\"{category} accuracy: {comp[True] * 100}%%\")\n",
    "\n",
    "df.sort_index(axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some expected failures. For example:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src='https://assets-prd.ignimgs.com/2022/10/26/18-050l-2-eg-1666822378783.jpg' /></td>\n",
    "        <td><img src='https://www.legendarywolfgames.com/wp-content/uploads/2020/03/FFTCG-PR072.jpg' /></td>\n",
    "        <td><img src='http://img.over-blog-kiwi.com/2/21/23/79/20181209/ob_78f42c_y-shtola.jpg' /></td>\n",
    "        <td><img src='https://i.ebayimg.com/images/g/e60AAOSwerdand5v/s-l500.jpg' /></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The first card, Yuffie, is a speciall Full Art card. It has very limit features a machine mind find to determine say, the correct *Element*. Alternatively, the *Power* is quite prominent but we never trained the models on Full Art cards. Regardless it is suprising it couldn't make out these numeric features.\n",
    "\n",
    "The second card, Chelinka, follows the same issues as the first card.\n",
    "\n",
    "The third card, Y'shtola, also has the same issues as above but is also has the foiling process and a white border around the card. I suspsect this would be the most difficult one to get right.\n",
    "\n",
    "The fourth card, Kain, is rather small/has a larger black background. Even though it is not a full art card, this could still be an issue without cropping or having object detection."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still alot more work to be done, especially considing our *Cost* accuracy is so low. Moreover, *Power* could easily be lower if more testing data actually had more cards with *Power*.\n",
    "\n",
    "The following cards have less obvious issues and require more investigation:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src='https://i.ebayimg.com/images/g/YuAAAOSwZxNjfXJn/s-l1600.jpg' /></td>\n",
    "        <td><img src='https://cdn.shopify.com/s/files/1/1715/6019/products/AsheEXFullArt_Foil_500x.png' /></td>\n",
    "        <td><img src='https://i.ebayimg.com/images/g/fnMAAOSwaHdhcz6-/s-l500.jpg'/></td>\n",
    "        <td><img src='https://i.ebayimg.com/images/g/rTkAAOSw7wljo1MD/s-l500.jpg' /></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The first card, Ifrit, is mostly corect except our Ensemble model does not (nor does any of the contributing models on further inspection) see that it does have *Ex_Burst*. The *Cost* is also incorrect. At the time of writing this, I am curious if soft voting ensembling could improve *Cost* models overall.\n",
    "\n",
    "The second card, Ashe, has correct *Type_En* and *Ex_burst* but its *Power* is incorrect (though it > 0 which is a step in the right direction) and its *Element* is assumed to be light, which might be due to the foil process. The *Cost* is also incorrect.\n",
    "\n",
    "The third card, Laguna, has correct *Element* and *Type_EN* but its *Power*, *Ex_Burst*, and *Cost* are off. I cannot by looking at it why things are off. Could it be due the white bottom-border?\n",
    "\n",
    "The forth card, Sephiroth, has a big white border on the top and bottom.\n",
    "\n",
    "If we drop all these problematic cards then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element accuracy: 88.57142857142857%%\n",
      "Type_EN accuracy: 100.0%%\n",
      "Cost accuracy: 82.85714285714286%%\n",
      "Power accuracy: 88.57142857142857%%\n",
      "Ex_Burst accuracy: 97.14285714285714%%\n"
     ]
    }
   ],
   "source": [
    "df2 = df.reset_index().drop([2, 3, 4, 5, 17, 26, 27, 32])\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    comp = df2[category] == df2[f\"{category}_yhat\"]\n",
    "    comp = comp.value_counts(normalize=True)\n",
    "    print(f\"{category} accuracy: {comp[True] * 100}%%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "#### Object Detection\n",
    "\n",
    "To further follow the inspiration projects, multiple-card (object) detection is a new goal. `openCV` is a great library for working with video and cameras. It even offers some support to run through various DNNs (Deep Neural Networks). At this current stage, the whole image (camera feed) would be processed per frame, regardles if there is a valid card there or not.\n",
    "\n",
    "`freezegraph.py` is my script to convert saved models to the form openCV can use.\n",
    "\n",
    "`testfrozen.py` is my script to test these convert models. Curiously, openCV's loading *Power* returns a different value than in testmodel\n",
    "\n",
    "[YOLO Dectection](https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/) might be useful. This might require not only gather more real-world images but also annotating them; essentially creating a \"Is FFTCG Card\" model. From here we could do some second pass with these feature models to derive what the card is (or gather lots of images of each of the tens of thousand unique of cards out there).\n",
    "\n",
    "Some image annotating tools I've found are [CVAT](https://blog.roboflow.com/cvat/) and [LabelImg](https://blog.roboflow.com/labelimg/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e824e46d66b8419a9ecf8137d23a7da9a487b368cc009f6ab1e15cc6af4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
